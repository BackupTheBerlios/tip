#! /bin/bash
# A really crude implementation of web profiler

# If you need to profile a page as logged-in user, copy here cookies.txt from
# your browser cache and append ' --load-cookies ./cookies.txt' to the
# following command
READER='wget -qpkO /dev/null --no-cache'
URL=''
TIMES=10

if [ "x$1" == "x" ]; then
  echo "Usage: $0 URL [TIMES]"
  echo "where TIMES is the number of times the page must be read (default 10)"
  exit 1
else
  URL=$1
fi

if [ "x$2" != "x" ]; then
  TIMES=$2
fi

echo
echo "                URL: $URL"

echo -n " Discarding 4 pages: "
{ time for((n=0; n<4; ++n)); do $($READER $URL); echo -n .; done; } 2>/dev/null
echo

echo -n "   Reading $TIMES pages: "
{ time for((n=0; n<$TIMES; ++n)); do $($READER $URL); echo -n .; done; } 2>result
echo

echo -n "Estimated page time: "
eval "`sed -ne 's/^real[[:space:]]*\([0-9]\+\)m\([0-9]\+\)\.0\?0\?\([0-9]\+\)s/MINUTES=\1; SECONDS=\2; MICRO=\3/p' result`"
rm result
(( TOTAL = MINUTES*60000 + SECONDS*1000 + MICRO ))
(( TEST = TOTAL / TIMES ))
(( TEST_SECONDS = TEST / 1000 ))
(( TEST_MICRO = TEST % 1000 ))
printf -v RESULT "%d.%03d seconds" $TEST_SECONDS $TEST_MICRO
echo $RESULT

echo -n "     Logging result: "
DATE=`date +%F`
LINE="$DATE $RESULT ($URL)"
if [ -w profiler.log ]; then
  sed -i -e "\|$DATE .* ($URL)| d" profiler.log
fi
echo $LINE >> profiler.log
echo "done."

echo
